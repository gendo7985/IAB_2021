{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ec1NCtLafD2"
   },
   "source": [
    "# 1. Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFpwJWt6H8i-"
   },
   "source": [
    "### 1-1. Import Libraries\n",
    "- 데이터셋 다운로드와 전처리를 쉽게 하는 torchtext 라이브러리를 import 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fuWiZzTJIHlX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.legacy import data, datasets\n",
    "\n",
    "import random\n",
    "import time\n",
    "import spacy\n",
    "import numpy as np\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlBRh_erIV5Y"
   },
   "source": [
    "### 1-2. Load data\n",
    "- Field 를 정의합니다.\n",
    "- IMDB 데이터를 다운받습니다.\n",
    "- Train, Valid, Test 데이터셋으로 split 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1qAjGhs_momr"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(include_lengths=True)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lAyLqGf_sOgf"
   },
   "outputs": [],
   "source": [
    "# Download IMDB data\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xhhfnEZYsld1"
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9dDuDBdvsOmk"
   },
   "outputs": [],
   "source": [
    "# Split train and valid data\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdLyvaV6o-TY",
    "outputId": "2a260341-7d22-4043-90a8-e89f2f65fab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print('Number of training examples: {}'.format(len(train_data)))\n",
    "print('Number of validation examples: {}'.format(len(valid_data)))\n",
    "print('Number of testing examples: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEsf_UifafEH"
   },
   "source": [
    "### 1-3. Cuda Setup\n",
    "- GPU 사용을 위한 Cuda 설정\n",
    "- Colab 페이지 상단 메뉴>수정>노트설정에서 GPU 사용 설정이 선행되어야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "W4BsnajZafEI"
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8fuDdBOafEO",
    "outputId": "d77cc82b-a846-4151-8f19-184232afe4cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 10 16:14:10 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 166...  Off  | 00000000:0A:00.0  On |                  N/A |\r\n",
      "|  0%   50C    P5    13W / 125W |    499MiB /  5941MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1200      G   /usr/lib/xorg/Xorg                 59MiB |\r\n",
      "|    0   N/A  N/A      1764      G   /usr/lib/xorg/Xorg                232MiB |\r\n",
      "|    0   N/A  N/A      1909      G   /usr/bin/gnome-shell               39MiB |\r\n",
      "|    0   N/A  N/A      3151      G   ...AAAAAAAAA= --shared-files      101MiB |\r\n",
      "|    0   N/A  N/A      5676      G   ...AAAAAAAAA= --shared-files       31MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kC9xHrlt4LL9"
   },
   "source": [
    "## 2. Preprocess data\n",
    "- Vocab (단어장) 을 만듭니다.\n",
    "- Iterator 를 만듭니다. (Iterator 를 통해 batch training 을 위한 batching 과 padding, 그리고 데이터 내 단어들의 인덱스 변환이 이루어집니다.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "suJRz9fgur1_"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data,\n",
    "                 max_size = MAX_VOCAB_SIZE,\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_                 \n",
    "                 )\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ES2qQ9kdu71e",
    "outputId": "5a267b93-0f32-4a6e-c805-015210044426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sOD6AiIwKu-G"
   },
   "outputs": [],
   "source": [
    "# Batching - construct iterator\n",
    "BATCH_SIZE = 4\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_sizes = (BATCH_SIZE, BATCH_SIZE, BATCH_SIZE),\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wbuiZUpjhEqe"
   },
   "outputs": [],
   "source": [
    "for batch in test_iterator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iy8D6z9FkKEJ",
    "outputId": "44772f3a-09c6-4025-e762-708d83e1f9e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GXQ3jpqOkSRk"
   },
   "outputs": [],
   "source": [
    "\n",
    "for batch in train_iterator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDjs5v3BkUG1",
    "outputId": "8c49b6af-a40d-46f6-b2b5-ae2f337e18da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   49, 11413,   129,  1489],\n",
       "        [   23,    43, 17376,   101],\n",
       "        [    7,    12, 14788,     3],\n",
       "        [   41,   200,   644,   642],\n",
       "        [    3,    26,     7,   392],\n",
       "        [  879,    27,    20,     5],\n",
       "        [  295,     2,     2,  1972],\n",
       "        [   35, 17332,     0,  4897],\n",
       "        [   40,     0,     4,     4],\n",
       "        [   33,     5,   106,  4976],\n",
       "        [ 3360,     2, 14798, 24872],\n",
       "        [   16,     0,  6369,   605],\n",
       "        [    0,     0,   214,    12],\n",
       "        [   20, 13247,    27,   268],\n",
       "        [    0,    34,    24,   327],\n",
       "        [   13,     2,   414,    41],\n",
       "        [   93,   706,  2589,  1940],\n",
       "        [  134,  1076,     5,   191],\n",
       "        [    7,    10,     0,  1168],\n",
       "        [  397,     9,     8,    10],\n",
       "        [13450,    98,    11,     9],\n",
       "        [    9,  1237,  6735,    90],\n",
       "        [ 2060,     3,  5064,   207],\n",
       "        [    6,   162,  3219,     0],\n",
       "        [   66,     0,     2,     2],\n",
       "        [   94,    18,     0,     0],\n",
       "        [    0,    12,     0,     9],\n",
       "        [   42,     7,   158,   638],\n",
       "        [    0,     3, 11648,    37],\n",
       "        [    0,    60,  1460,     2],\n",
       "        [   19,    97,   185,   889],\n",
       "        [  134,    23,     5,    34],\n",
       "        [  475,    41,   732,    33],\n",
       "        [   33,  1186,     6,   184],\n",
       "        [ 2330,     0,    66,     0],\n",
       "        [  748,     0,     8,  2318],\n",
       "        [  923,  2184,    11,  5693],\n",
       "        [   74,     0,   682,     0],\n",
       "        [    3,   192,     2,    18],\n",
       "        [23297,   118,  5086,   638],\n",
       "        [20193,     0,    22,   185],\n",
       "        [  135,     4,  1350,     5],\n",
       "        [ 4707,     2, 12640,     2],\n",
       "        [    2, 12478,     4,  5665],\n",
       "        [  166,   201,    52,    13],\n",
       "        [   10,   100,    38,  5039],\n",
       "        [   22,   708,    87,   173],\n",
       "        [  936,     8,  3629,     2],\n",
       "        [    8,     0,   313,   889],\n",
       "        [ 2576,   371, 11456,    22],\n",
       "        [ 2578,    24,    56,  6477],\n",
       "        [   22,  2126,    88,     4],\n",
       "        [  427,    19,  1468,  4976],\n",
       "        [ 2218,   292,  4659, 24872],\n",
       "        [   99,     7,    74,   123],\n",
       "        [  599,   397,     2,     7],\n",
       "        [    5,  5876,  1660,  1544],\n",
       "        [ 2576,     8,    17,     4],\n",
       "        [14645,    68,    67,   824],\n",
       "        [  138,  1148,   316,    28],\n",
       "        [   15,    28,    51,    39],\n",
       "        [    2,  7425,    43,   187],\n",
       "        [ 8451,     6,  1599,    36],\n",
       "        [    8,   212,     9,     0],\n",
       "        [    2,    11,   373,     0],\n",
       "        [  815,  4684, 11114,   468],\n",
       "        [    5,    12,   109,   248],\n",
       "        [    2,     7,   164,     6],\n",
       "        [ 5290,   336,    12,    85],\n",
       "        [  394,     3,    15,    59],\n",
       "        [  708,   439,    58,     6],\n",
       "        [ 9174,     4,    68,    24],\n",
       "        [    4,  5983,  1723, 12525],\n",
       "        [ 4943,    59,    14, 10456],\n",
       "        [    0,     2,     0,    30],\n",
       "        [ 4911,  9190,     4,  6618],\n",
       "        [    2,  1040, 23207,     0],\n",
       "        [  208,     4,    45,    44],\n",
       "        [  159,   229,    68,  2724],\n",
       "        [    9,     8, 17696,   422],\n",
       "        [  369,     3,   113,   123],\n",
       "        [  578,   434,    12,   148],\n",
       "        [   10,  6172,  1330,    25],\n",
       "        [  256,   113,   205,     2],\n",
       "        [    0,     2,     3,   747],\n",
       "        [    0,    21,   872,  1623],\n",
       "        [    7,   542,  3043,     4],\n",
       "        [ 4313,   275, 11393,     0],\n",
       "        [    2,    45,   262,     5],\n",
       "        [  879,     3,   117,     2],\n",
       "        [ 1689,   339,   152,    82],\n",
       "        [    4,   720,   325, 23308],\n",
       "        [    2,    61,   578,  4897],\n",
       "        [ 2576,   290,     5,  4349],\n",
       "        [ 2578,   315,  2839,    13],\n",
       "        [    0,   130,    12, 13860],\n",
       "        [   13,     4,    79,   164],\n",
       "        [ 5900,   130,     5,    17],\n",
       "        [    0,   775,  6963,     2],\n",
       "        [    0,     0,     0,   889],\n",
       "        [    7,    58,     0,     4],\n",
       "        [    3,    28,   219,     3],\n",
       "        [    0,    36,   343,    97],\n",
       "        [  305,  2909,     0,  7578],\n",
       "        [  549,  2184,   663,  9033],\n",
       "        [  142, 11411,     0,  3421],\n",
       "        [14024,   839,    13,    29],\n",
       "        [  783,     9,  1283,  4976],\n",
       "        [  293, 15660,  5349, 17239],\n",
       "        [   34,     5,  7420,     1],\n",
       "        [  114,  4917,     1,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_tAoIcUMp3v"
   },
   "source": [
    "## 3. Build Model\n",
    "- Embedding layer, Transformer layer, Fully-connected layer 로 이루어진 모델을 만듭니다.\n",
    "- Classification task 에 활용하기 위해 기존 Seq2Seq Transformer 를 변형하여, Transformer Encoder 만을 활용합니다.\n",
    "- Positional Encoding 식\n",
    "> $PE_(pos,2i) =sin(pos/10000^{2i/d_{model}})$  \n",
    "> $PE_(pos,2i+1) =cos(pos/10000^{2i/d_{model}})$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XB9WQX3yrC2P"
   },
   "outputs": [],
   "source": [
    "class PositionalEnc(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6slAdlS5giEY"
   },
   "outputs": [],
   "source": [
    "class TransformerNet(nn.Module):    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_heads, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define parameters\n",
    "        self.hidden_him = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Define Layers\n",
    "        # TO-DO Embedding layer\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        self.pe =  PositionalEnc(embedding_dim)\n",
    "      \n",
    "        # Encoder layer\n",
    "        enc_layer = nn.TransformerEncoderLayer(embedding_dim, n_heads, hidden_dim, dropout=dropout)\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n",
    "      \n",
    "        # TO-DO Fully connected layer and Dropout layer\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text = [sent len, batch size]\n",
    "\n",
    "        # TO-DO Transformer 가 출력한 output 의 평균값을 Dropout, FC layer 을 통과하여 반환\n",
    "        # hint\n",
    "        # embedded : [sent len, batch size, emb dim]\n",
    "        # trans_out : [sent len, batch_size, emb_dim]\n",
    "        # pooled : transformer 출력의 평균\n",
    "        # final : Dropout -> FC 통과한 logits\n",
    "\n",
    "        embedded =  self.embedding(text)\n",
    "        pos_encoded = self.pe(embedded)\n",
    "        trans_out = self.encoder(pos_encoded)       \n",
    "        pooled = trans_out.mean(0) \n",
    "        final = self.fc(self.dropout(pooled))\n",
    "\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9fTDWd8RhEEl"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 1\n",
    "N_HEADS = 2  #embedding_dim must be divisible by n_heads\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = TransformerNet(input_dim=INPUT_DIM,      \n",
    "                       embedding_dim=EMBEDDING_DIM, \n",
    "                       hidden_dim=HIDDEN_DIM, \n",
    "                       output_dim=OUTPUT_DIM, \n",
    "                       n_heads=N_HEADS,\n",
    "                       n_layers=N_LAYERS, \n",
    "                       dropout=DROPOUT,\n",
    "                       pad_idx=PAD_IDX)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCUKXn94afEf",
    "outputId": "67f2679a-5c62-4b85-e2a3-6fd45a03a022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,566,929 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('The model has {:,} trainable parameters'.format(count_parameters(model)))\n",
    "\n",
    "# load pretrained embeddings\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDy-PGhSQcTd"
   },
   "source": [
    "## 4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "s7-5uM9bhTe3"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model= model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7exIxGaZafE4"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1Eb16jU0afFA"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        # TO-DO\n",
    "        # General Training Scheme\n",
    "        optimizer.zero_grad()    \n",
    "        prediction = model(batch.text[0]).squeeze(1)\n",
    "        loss = criterion(prediction, batch.label)\n",
    "        acc = binary_accuracy(prediction, batch.label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8da_fbPRQ9I3"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            # TO-DO\n",
    "            # General Evaluation Scheme\n",
    "            prediction = model(batch.text[0]).squeeze(1)\n",
    "            loss = criterion(prediction, batch.label)\n",
    "            acc = binary_accuracy(prediction, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZhS9Q2fSLyr"
   },
   "source": [
    "### *Do Training!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K46LhrQ7012J",
    "outputId": "4f42dfd1-c654-40d2-f530-33c3fda06a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.500 | Train Acc: 74.29%\n",
      "\t Val. Loss: 0.402 |  Val. Acc: 83.20%\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.311 | Train Acc: 87.32%\n",
      "\t Val. Loss: 0.491 |  Val. Acc: 83.91%\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.243 | Train Acc: 90.39%\n",
      "\t Val. Loss: 0.449 |  Val. Acc: 84.67%\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.200 | Train Acc: 92.17%\n",
      "\t Val. Loss: 0.588 |  Val. Acc: 83.33%\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.176 | Train Acc: 93.06%\n",
      "\t Val. Loss: 0.509 |  Val. Acc: 84.19%\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.152 | Train Acc: 94.39%\n",
      "\t Val. Loss: 0.673 |  Val. Acc: 82.75%\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.134 | Train Acc: 95.06%\n",
      "\t Val. Loss: 0.603 |  Val. Acc: 84.60%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 7\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    if valid_loss < best_valid_loss: # For early stopping\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'trans-model.pt') # Save the model\n",
    "    \n",
    "    print('Epoch: {:02}'.format(epoch+1))\n",
    "    print('\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%'.format(train_loss, train_acc*100))\n",
    "    print('\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%'.format(valid_loss, valid_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "En4SX_RA02k4",
    "outputId": "66c112e5-6034-4c68-c584-22d7061214f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.387 | Test Acc: 83.74%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('trans-model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "\n",
    "print('Test Loss: {:.3f} | Test Acc: {:.2f}%'.format(test_loss, test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EtTQaIdafFL"
   },
   "source": [
    "## 5. Test model\n",
    "우리가 직접 예문을 작성해서 트레인된 모델에서 예문을 어떻게 평가하는지 확인합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "_hxev65tafFQ"
   },
   "outputs": [],
   "source": [
    "# 토크나이저로 spacy 를 사용합니다.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# 사용자가 입력한 sentence 를 훈련된 모델에 넣었을때의 결과값을 확인합니다.\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  # Tokenization\n",
    "    print(tokenized)\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]   # 위에서 만든 vocab 에 부여된 index 로 indexing\n",
    "    print(indexed)\n",
    "    tensor = torch.LongTensor(indexed).to(device)   # indexing 된 sequence 를 torch tensor 형태로 만들어줌.\n",
    "    print(tensor.shape)\n",
    "    tensor = tensor.unsqueeze(1)   # 입력 텐서에 batch 차원을 만들어줌.\n",
    "    prediction = torch.sigmoid(model(tensor))  # 모델에 입력한 후 확률값 도출을 위한 sigmoid 적용 \n",
    "    return prediction.item() # prediction 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIk_EjmoSFdU",
    "outputId": "d0907fc8-112f-4cfb-a356-7e4954d5b3c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'film', 'is', 'terrible']\n",
      "[49, 23, 7, 538]\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0014805947430431843"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is terrible\") #아주 낮은 값의 확률이 도출되는 것을 확인할 수 있습니다.(부정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1ZZJbxaSFaa",
    "outputId": "8b0f2a3e-1035-4874-dd4c-ab64a687e944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'film', 'is', 'great']\n",
      "[49, 23, 7, 97]\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9992258548736572"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is great\") #아주 높은 값의 확률이 도출되는 것을 확인할 수 있습니다. (긍정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRQZvw-z26CD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wahPDnJKka-L"
   },
   "source": [
    "# Homework (Part2-2) \n",
    "## LSTM + Self-attention Model for Text Classification\n",
    "- Attention mechanism 을 통해 마지막 순서와 각 순서와의 관계 고려하기.\n",
    "- (1) Embedding layer\n",
    "- (2) LSTM layer\n",
    "- (3) Self-attention layer: LSTM 의 마지막 representation 을 추출하여 Self-Attention 으로 representation 업데이트\n",
    "- (4) Dropout layer\n",
    "- (5) Fully-connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "dr2tzUxake0Z"
   },
   "outputs": [],
   "source": [
    "class Self_Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.scale = 1. / math.sqrt(hidden_dim)\n",
    "\n",
    "    def forward(self, query, key, value): \n",
    "        # query == hidden: = [N, H]\n",
    "        # key/value == output: [L, N, H]\n",
    "\n",
    "        ### Key 텐서의 크기를 재배열 ###\n",
    "        query = query.unsqueeze(1) # [N, 1, H]\n",
    "        key = key.permute(1,2,0)  # [N, H, L]  \n",
    "\n",
    "        # bmm: batch matrix-matrix multiplication\n",
    "        # Query 값과 key 의 각 토큰값 간의 Dot-product\n",
    "        attention_weight = torch.bmm(query, key)  # [N, 1, L] \n",
    "\n",
    "        # Scale and normalize\n",
    "        attention_weight = F.softmax(attention_weight.mul_(self.scale), dim=2) # [N, 1, L]\n",
    "\n",
    "        # Attention weight 과 value 곱해서 attention output 구하기\n",
    "        # Value 텐서의 크기를 재배열\n",
    "        value =  value.transpose(0,1)            # [N, L, H]\n",
    "        attention_output = torch.bmm(attention_weight, value)   # [N, 1, H]\n",
    "        attention_output = attention_output.squeeze(1) # [N, H]\n",
    "\n",
    "        return attention_output, attention_weight.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "4Tt86vDfkzLg"
   },
   "outputs": [],
   "source": [
    "# Make Custom GRU + Self-attention Model\n",
    "\n",
    "class CustomModel(nn.Module): \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define parameters\n",
    "        self.hidden_him = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Define Embedding Layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
    "        # Define Layers\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        # Attention layer\n",
    "        self.attention = Self_Attention(hidden_dim)\n",
    " \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        query, (key, value) = self.lstm(embedded)\n",
    "        post_att = self.attention(query=query[-1,:,:], key=key, value=value)\n",
    "        output = self.fc(self.dropout(post_att[0]))\n",
    "        '''\n",
    "        Homework (2-2)\n",
    "        Apply GRU and Dropout, then Self-Attention\n",
    "        Use the last hidden representation of the sequence\n",
    "        hint: \n",
    "        1) self.lstm(XX) Remind that lstm layer returns a tuple\n",
    "        2) self.attention(query=XX, key=XX, value=XX) \n",
    "            * Use the last representation of LSTM outputs as query\n",
    "            * query tensor shape: [N, H]\n",
    "        3) self.dropout(XX)\n",
    "        4) self.fc(XX)\n",
    "        '''\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "u3cRVpYKk3g5"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.1\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CustomModel(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS,\n",
    "            DROPOUT, \n",
    "            PAD_IDX)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdIjZr_bk_er",
    "outputId": "9264c6dc-6dcb-43ad-bc96-9e17253d7a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,750,185 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# CustomModel 의 파라미터 수 확인\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)  # Count number of elements of all parameters\n",
    "\n",
    "print('The model has {:,} trainable parameters'.format(count_parameters(model))) # 2,750,185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A0BJywNblA1S",
    "outputId": "06df7253-ca4c-40f5-9294-fe5b4da0ba82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# load pretrained embeddings\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(type(pretrained_embeddings))\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "AZ5AXWYVlChG"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()  # 손실함수 정의 \n",
    "model = model.to(device)  #모델을 GPU 로 이동\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLl7qbsPlPdx",
    "outputId": "3b7ae80e-7d6f-4d93-efec-bfeab83e3859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.514 | Train Acc: 72.00%\n",
      "\t Val. Loss: 0.326 |  Val. Acc: 86.47%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf') # Represents infinity\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    if valid_loss < best_valid_loss: # For early stopping\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'custom_model.pt')\n",
    "    else:\n",
    "      break\n",
    "    \n",
    "    print('Epoch: {:02}'.format(epoch+1))\n",
    "    print('\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%'.format(train_loss, train_acc*100))\n",
    "    print('\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%'.format(valid_loss, valid_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "O3i1vM-alU05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.324 | Test Acc: 86.41%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('custom_model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print('Test Loss: {:.3f} | Test Acc: {:.2f}%'.format(test_loss, test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByA4BD62lljP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fall2021_IAB_Transformer_FullVersion.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
