{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ec1NCtLafD2"
   },
   "source": [
    "## 1. Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFpwJWt6H8i-"
   },
   "source": [
    "### 1-1. Import Libraries\n",
    "- 데이터셋 다운로드와 전처리를 쉽게 하는 torchtext 라이브러리를 import 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fuWiZzTJIHlX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.legacy import data, datasets\n",
    "import time\n",
    "import spacy\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlBRh_erIV5Y"
   },
   "source": [
    "### 1-2. Load data\n",
    "- Field 를 정의합니다.\n",
    "- IMDB 데이터를 다운받습니다.\n",
    "- Train,valid,test 데이터셋으로 split 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1qAjGhs_momr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zendo/anaconda3/lib/python3.8/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(tokenize='spacy',include_lengths=True)\n",
    "LABEL = data.LabelField(dtype = torch.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lAyLqGf_sOgf"
   },
   "outputs": [],
   "source": [
    "# Download IMDB data (about 3mins)\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xhhfnEZYsld1"
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9dDuDBdvsOmk"
   },
   "outputs": [],
   "source": [
    "# Split train and valid data\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1625727005512,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "NdLyvaV6o-TY",
    "outputId": "c7f8e77d-58c7-42f3-f89a-f0c39d747130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print('Number of training examples: {}'.format(len(train_data)))\n",
    "print('Number of validation examples: {}'.format(len(valid_data)))\n",
    "print('Number of testing examples: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1625727005512,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "upDGRwQPDa30",
    "outputId": "a8b217ae-243b-4b35-de12-d71bd4a3e10b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['The', 'TV', 'guide', 'described', 'the', 'plot', 'of', 'SEVERED', 'TIES', 'as', 'thus', ':', '\"', 'An', 'experiment', 'on', 'a', 'severed', 'arm', 'goes', 'awry', '\"', 'so', 'right', 'away', 'I', 'thought', 'this', 'was', 'going', 'to', 'be', 'about', 'an', 'arm', 'that`s', 'got', 'a', 'mind', 'of', 'its', 'own', 'as', 'seen', 'in', 'THE', 'BEAST', 'WITH', 'FIVE', 'FINGERS', 'or', 'THE', 'HAND', 'or', 'someone', 'getting', 'an', 'arm', 'transplant', 'as', 'in', 'BODY', 'PARTS', '.', 'Both', 'premises', 'are', 'tried', 'and', 'tested', ',', 'or', 'to', 'be', 'more', 'accurate', 'tired', 'and', 'tested', 'so', 'I', 'was', 'curious', 'as', 'to', 'how', 'the', 'producers', 'would', 'approach', 'the', 'story', '.', 'I', 'actually', 'thought', 'they', 'were', 'making', 'an', 'arthouse', 'movie', 'like', 'PI', 'down', 'to', 'the', 'use', 'of', 'B&W', 'photography', 'at', 'the', 'start', 'of', 'the', 'film', 'but', 'the', 'makers', 'seemed', 'to', 'have', 'tired', 'of', 'this', 'approach', 'after', '20', 'seconds', 'and', 'decided', 'to', 'make', 'a', 'splatter', 'comedy', 'similar', 'to', 'THE', 'EVIL', 'DEAD', '.', 'I`ve', 'very', 'little', 'to', 'say', 'on', 'this', 'except', 'that', 'I', 'disliked', 'THE', 'EVIL', 'DEAD', 'movies', 'and', 'I', 'disliked', 'SEVERED', 'TIES', 'and', 'it', 'seems', 'really', 'unfair', 'that', 'films', 'like', 'this', 'use', 'an', 'obscene', 'amount', 'of', 'rubber', 'when', 'the', 'third', 'world', 'is', 'crying', 'out', 'for', 'condoms'], 'label': 'neg'}\n"
     ]
    }
   ],
   "source": [
    "# print example\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1625727005512,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "eXK5geJ9DvZN",
    "outputId": "61e0238c-2bd0-4d39-98e1-44dcdf60327e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TV guide described the plot of SEVERED TIES as thus : \" An experiment on a severed arm goes awry \" so right away I thought this was going to be about an arm that`s got a mind of its own as seen in THE BEAST WITH FIVE FINGERS or THE HAND or someone getting an arm transplant as in BODY PARTS . Both premises are tried and tested , or to be more accurate tired and tested so I was curious as to how the producers would approach the story . I actually thought they were making an arthouse movie like PI down to the use of B&W photography at the start of the film but the makers seemed to have tired of this approach after 20 seconds and decided to make a splatter comedy similar to THE EVIL DEAD . I`ve very little to say on this except that I disliked THE EVIL DEAD movies and I disliked SEVERED TIES and it seems really unfair that films like this use an obscene amount of rubber when the third world is crying out for condoms\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(vars(train_data.examples[0])['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEsf_UifafEH"
   },
   "source": [
    "### 1-3. Cuda Setup\n",
    "- GPU 사용을 위한 Cuda 설정\n",
    "- Colab 페이지 상단 메뉴>수정>노트설정에서 GPU 사용 설정이 선행되어야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "W4BsnajZafEI"
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzAMPhQ2D5E3"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1625727005920,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "c8fuDdBOafEO",
    "outputId": "305e038c-c1f3-4690-df2c-937ec65275a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 10 16:42:47 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 166...  Off  | 00000000:0A:00.0  On |                  N/A |\r\n",
      "|  0%   45C    P8    12W / 125W |    466MiB /  5941MiB |      9%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1200      G   /usr/lib/xorg/Xorg                 59MiB |\r\n",
      "|    0   N/A  N/A      1764      G   /usr/lib/xorg/Xorg                238MiB |\r\n",
      "|    0   N/A  N/A      1909      G   /usr/bin/gnome-shell               44MiB |\r\n",
      "|    0   N/A  N/A      3151      G   ...AAAAAAAAA= --shared-files       56MiB |\r\n",
      "|    0   N/A  N/A      5676      G   ...AAAAAAAAA= --shared-files       31MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kC9xHrlt4LL9"
   },
   "source": [
    "##2. Preprocess data\n",
    "- Vocab (단어장) 을 만듭니다.\n",
    "- Iterator 를 만듭니다. (Iterator 를 통해 batch training 을 위한 batching 과 padding, 그리고 데이터 내 단어들의 인덱스 변환이 이루어집니다.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snEZbJb4WBZS"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained word vectors (about 7mins)\n",
    "TEXT.build_vocab(train_data, vectors = \"glove.6B.100d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgqlvMLhFxmS"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1625727008212,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "1fNOoZwZurdQ",
    "outputId": "0c202cbb-cb89-48b2-c5cf-263b2dd47ed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 102064\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "suJRz9fgur1_"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data,\n",
    "                 max_size = MAX_VOCAB_SIZE,\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_                 \n",
    "                 )\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1625727009848,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "ES2qQ9kdu71e",
    "outputId": "b53f30e4-eb69-46e7-8d9c-f1f77075be4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1625727009848,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "692haI3q1XZm",
    "outputId": "6fcced1b-ba45-49bb-c9cf-2a8bcb10d697"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:10]  #itos – A list of token strings indexed by their numerical identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1625727009848,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "TolmqsvNvoCD",
    "outputId": "6fb634de-acaf-431f-bf11-f85a7e8e36fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25002\n",
      "0 1\n"
     ]
    }
   ],
   "source": [
    "word_dict = TEXT.vocab.stoi # stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
    "print(len(word_dict))\n",
    "print(word_dict['<unk>'], word_dict['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1625727009849,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "JUCn66DV3EQS",
    "outputId": "0409944f-5434-4e1e-9de4-196e42016529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25002, 100])\n",
      "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
      "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
      "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
      "        ...,\n",
      "        [-0.0038,  0.5892, -0.3353,  ...,  0.3862,  0.1623,  0.7502],\n",
      "        [ 0.7290, -1.2762, -0.1884,  ...,  0.4076,  0.1942,  0.0521],\n",
      "        [ 0.7557,  0.4154,  0.3530,  ..., -0.3626, -0.9909,  1.0656]])\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.vectors.shape)\n",
    "print(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gvmmOAIPJTA5"
   },
   "outputs": [],
   "source": [
    "# Batching - construct iterator\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator = data.Iterator(\n",
    "    train_data, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1625727010252,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "vP72ZzRBIyi9",
    "outputId": "a8ba8ac9-ce7f-43ae-d0a7-6fe8b4c28de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 325,  159,  314,  ...,   16,   66,  531],\n",
      "        [  67,  549,   11,  ...,    9,   98,   85],\n",
      "        [  15, 5340,  240,  ...,    5,   36,   29],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0'), tensor([236, 230, 282, 201, 135,  82, 235, 181, 450, 185, 146, 680, 204,  80,\n",
      "        152,  98,  92, 116, 399, 141, 117, 166, 502, 329, 112, 132, 243, 145,\n",
      "        747,  64, 177, 199], device='cuda:0'))\n",
      "747\n",
      "torch.Size([747, 32])\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# shape: BATCH_SIZE x maximum length of sentence \n",
    "for batch in train_iterator:\n",
    "    break\n",
    "print(batch.text)\n",
    "print(len(batch.text[0]))\n",
    "print(batch.text[0].shape) # [seq len, batch_size]\n",
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_uKU20YTxgaQ"
   },
   "outputs": [],
   "source": [
    "# BucketIterator\n",
    "\n",
    "train_iterator = data.BucketIterator(\n",
    "    train_data, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1625727010252,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "tpgFsjkgJLvx",
    "outputId": "e51cd547-ad1e-42de-b1f6-3ffc5982b560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 3327,   146,  2711,  ...,  3616,    66,    54],\n",
      "        [ 8903,   146,  2230,  ...,    20,    24,  1966],\n",
      "        [    9,   146,     9,  ...,  2427,    52,     2],\n",
      "        ...,\n",
      "        [   42, 19975,     7,  ...,     4,     4,     4],\n",
      "        [ 9155,     0,   317,  ...,     1,     1,     1],\n",
      "        [   39,    39,     4,  ...,     1,     1,     1]], device='cuda:0'), tensor([131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 130, 130, 130,\n",
      "        130, 130, 130, 130, 130, 130, 130, 130, 130, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129], device='cuda:0'))\n",
      "131\n",
      "torch.Size([131, 32])\n",
      "tensor([1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    break\n",
    "print(batch.text)\n",
    "print(len(batch.text[0]))\n",
    "print(batch.text[0].shape)\n",
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sOD6AiIwKu-G"
   },
   "outputs": [],
   "source": [
    "# Batching - construct iterator\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_sizes = (BATCH_SIZE, BATCH_SIZE, BATCH_SIZE),\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_tAoIcUMp3v"
   },
   "source": [
    "##3. Build Model\n",
    "- 텍스트를 입력받아 긍/부정 확률값을 출력하는 모델을 만듭니다.\n",
    "- 미리 학습된 워드 임베딩을 임베딩 레이어에 올립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_rzg3mj5apT"
   },
   "source": [
    "### 1) RNN Model for Text Classification\n",
    "- (1) Embedding layer : 각 토큰을 해당 워드 임베딩으로 바꿈.\n",
    "- (2) Vanilla RNN/ LSTM-RNN layer: 워드 임베딩의 시퀀스를 순차적으로 처리.\n",
    "- (3) Dropout layer: 일반화를 위해 임의의 유닛들을 0으로 바꿈.\n",
    "- (4) Fully-connected layer: RNN 으로 인코딩된 표현의 시퀀스 중 마지막 순서의 것을 취해 하나의 확률값으로 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-Jdh8JGOMyYq"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):  # Custom model 정의 \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define parameters\n",
    "        self.hidden_him = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Define Layers\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
    "        ### To-do ###\n",
    "        # Vanilla RNN layer\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        #############\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        # text = [L, N]   L = sentence length, N = batch size \n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        # embedded = [L, N, emb dim]      \n",
    "\n",
    "        # Apply RNN and Dropout\n",
    "        \n",
    "        ### To-do ###\n",
    "        output, hidden =  self.rnn(embedded)\n",
    "        #############\n",
    "\n",
    "        # hidden = [num_layers x num_directions, N, H]   H = hidden dimension\n",
    "\n",
    "        hidden = self.dropout(hidden[-1,:,:])\n",
    "\n",
    "        return self.fc(hidden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz7u51ACdAF1"
   },
   "source": [
    "\n",
    "### 주의사항\n",
    "* nn.RNN 모델은 biderectional 의 경우 forward layer 와 backward layer 총 2개 레이어를 가지게 됩니다.\n",
    "*   Torch.nn 제공 RNN 모듈은 2개의 아웃풋 중 하나로 hidden state 을 출력하며,\n",
    "> `output, hidden = self.rnn(embedded)`\n",
    "*   `hidden`은 모델에 들어있는 **모든 레이어**의 last hidden state 을 출력합니다.\n",
    "*   따라서 `hidden` 의 형태는 `[num_layers x num_directions, batch_size, hidden_size]`가 됩니다.\n",
    "\n",
    "* 모델에서 총 n개의 layer 를 사용할 경우, 순서대로 _1번째 forward, 1번째 backward, 2번째 forward, 2번째 backward, ..., n번째 forward, n번째 backward_ 가 표시됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1Q0Irr_7LES"
   },
   "source": [
    "### 2) Bi-LSTM Model for Text Classification\n",
    "- RNN layer 로서 Bidirectional LSTM layer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "FBD6lUpqe8eT"
   },
   "outputs": [],
   "source": [
    "# To-do: Make Custom Bidirectional LSTM Model\n",
    "\n",
    "class CustomModel(nn.Module): \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define parameters\n",
    "        self.hidden_him = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Define Layers\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        ### To-do ###\n",
    "        # Bidirectional LSTM-RNN layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional = True, dropout=dropout)\n",
    "        #############\n",
    " \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Fully connected layer\n",
    "        ### To-do ###\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        #############\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        # text = [L, N]   L = sentence length, N = batch size \n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        # embedded = [L, N, emb dim]      \n",
    "\n",
    "        # Apply Bidirectional LSTM and Dropout\n",
    "  \n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        # hidden = [num_layers x num_directions, N, H],   H = hidden dimension\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)) \n",
    "        \n",
    "        # hidden = [N, H]\n",
    "\n",
    "        return self.fc(hidden)     # [N, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "\n",
    "class CustomModel(nn.Module):  # Custom model 정의 \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define parameters\n",
    "        self.hidden_him = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Define Layers\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
    "        ### To-do ###\n",
    "        # Vanilla RNN layer\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        #############\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        # text = [L, N]   L = sentence length, N = batch size \n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        # embedded = [L, N, emb dim]      \n",
    "\n",
    "        # Apply RNN and Dropout\n",
    "        \n",
    "        ### To-do ###\n",
    "        output, hidden =  self.gru(embedded)\n",
    "        #############\n",
    "\n",
    "        # hidden = [num_layers x num_directions, N, H]   H = hidden dimension\n",
    "\n",
    "        hidden = self.dropout(hidden[-1,:,:])\n",
    "\n",
    "        return self.fc(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "n4EffzRaafEY"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.1\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CustomModel(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS,\n",
    "            DROPOUT, \n",
    "            PAD_IDX)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1625727903349,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "gCUKXn94afEf",
    "outputId": "cf12d0c2-b097-45b7-d230-f67fc6c9777d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,170,153 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)  # Count number of elements of all parameters\n",
    "\n",
    "print('The model has {:,} trainable parameters'.format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1625727903896,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "vgZ8wIYlG-_C",
    "outputId": "21f906c9-1db7-4423-fc74-53b5bb4f67e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# load pretrained embeddings\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(type(pretrained_embeddings))\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDy-PGhSQcTd"
   },
   "source": [
    "## 4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "09bHscfRG9ju"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())   # Gradient Descent 를 실행할 optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "YeZZ33ZeafEt"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()  # 손실함수 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "3bOa8C1tafEz"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)  #모델을 GPU 로 이동\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "7exIxGaZafE4"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    # To-do\n",
    "    #round predictions to the closest integer (Use torch.round() function)\n",
    "    round_preds = torch.round(torch.sigmoid(preds))\n",
    "    \n",
    "    #count the correct by building list of 0/1\n",
    "    correct = (round_preds==y).float()\n",
    "    \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "1Eb16jU0afFA"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "      \n",
    "        # Gradient 0으로 초기화\n",
    "        optimizer.zero_grad()        \n",
    "        \n",
    "        # Prediction \n",
    "        predictions = model(batch.text[0]).squeeze(1)\n",
    "        \n",
    "        # Loss 계산\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        # Accuracy 계산\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        # Backward pass (gradient 계산)\n",
    "        loss.backward()\n",
    "\n",
    "        # Parameter update\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "8da_fbPRQ9I3"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "          \n",
    "            predictions = model(batch.text[0]).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZhS9Q2fSLyr"
   },
   "source": [
    "### *Do Training!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50889,
     "status": "ok",
     "timestamp": 1625727958347,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "2uUWlVrUQ-lz",
    "outputId": "d0aeffeb-029f-4d6b-de3a-5022d20edaee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.042 | Train Acc: 98.87%\n",
      "\t Val. Loss: 0.367 |  Val. Acc: 89.31%\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.022 | Train Acc: 99.45%\n",
      "\t Val. Loss: 0.435 |  Val. Acc: 89.42%\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.022 | Train Acc: 99.35%\n",
      "\t Val. Loss: 0.512 |  Val. Acc: 88.52%\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.018 | Train Acc: 99.45%\n",
      "\t Val. Loss: 0.643 |  Val. Acc: 86.48%\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.012 | Train Acc: 99.67%\n",
      "\t Val. Loss: 0.524 |  Val. Acc: 88.59%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf') # Represents infinity\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    if valid_loss < best_valid_loss: # For early stopping\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'rnn-model.pt')\n",
    "    else:\n",
    "      pass\n",
    "    \n",
    "    print('Epoch: {:02}'.format(epoch+1))\n",
    "    print('\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%'.format(train_loss, train_acc*100))\n",
    "    print('\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%'.format(valid_loss, valid_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7652,
     "status": "ok",
     "timestamp": 1625727965991,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "3mXZ46wgRHWR",
    "outputId": "0fa2d954-901e-403c-8df1-feeacbfb092e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.392 | Test Acc: 88.23%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('rnn-model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print('Test Loss: {:.3f} | Test Acc: {:.2f}%'.format(test_loss, test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EtTQaIdafFL"
   },
   "source": [
    "## 5. Test model\n",
    "우리가 직접 예문을 작성해서 트레인된 모델에서 예문을 어떻게 평가하는지 확인합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hxev65tafFQ"
   },
   "outputs": [],
   "source": [
    "# 토크나이저로 spacy 를 사용합니다.\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# 사용자가 입력한 sentence 를 훈련된 모델에 넣었을때의 결과값을 확인합니다.\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  # Tokenization\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]   # 위에서 만든 vocab 에 부여된 index 로 indexing\n",
    "    tensor = torch.LongTensor(indexed).to(device)   # indexing 된 sequence 를 torch tensor 형태로 만들어줌.\n",
    "    tensor = tensor.unsqueeze(1)   # 입력 텐서에 batch 차원을 만들어줌.\n",
    "    prediction = torch.sigmoid(model(tensor))  # 모델에 입력한 후 확률값 도출을 위한 sigmoid 적용 \n",
    "    return prediction.item() # prediction 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1625727988157,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "dIk_EjmoSFdU",
    "outputId": "3a554c95-b9f3-47d2-d770-7f94bef3e4fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027659380808472633"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is terrible\") #아주 낮은 값의 확률이 도출되는 것을 확인할 수 있습니다.(부정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1625728001849,
     "user": {
      "displayName": "­곽희영",
      "photoUrl": "",
      "userId": "14765568829484274472"
     },
     "user_tz": -540
    },
    "id": "A1ZZJbxaSFaa",
    "outputId": "b5e9e83a-1eb3-4281-d5a4-fd55314ae0d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5428000092506409"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is not great\") #아주 높은 값의 확률이 도출되는 것을 확인할 수 있습니다. (긍정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDjerqMQRx9u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fall2021_IAB_학생용_RNNpractice_skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
